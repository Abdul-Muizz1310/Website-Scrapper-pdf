# ğŸ“š JavaScript.info PDF Scraper â€” Individual Article PDFs

This Python project crawls all tutorial pages on [https://javascript.info](https://javascript.info), extracts **only the core content**
(`<div itemprop="articleBody">`), removes all distractions like navigation bars, comments, links, and images, and then saves **each page as a clean PDF**.

> âœ… Perfect for offline study, archiving, or printing

---

## ğŸš€ Features

- ğŸ” Crawls every article on `https://javascript.info`
- ğŸ§½ Removes:
  - Navigation bars
  - Comments
  - Images and icons
  - Hyperlinks (text is preserved)
- âœ‚ï¸ Extracts only the main content (`articleBody`)
- ğŸ“„ Saves **one PDF per article**, using the URL path as the filename
- ğŸ–¨ï¸ PDF preserves original styles using **Playwright browser rendering**

---

## ğŸ§° Project Structure

```
website-scraper-pdf/
â”œâ”€â”€ output/                   # ğŸ“„ Individual PDF files go here
â”œâ”€â”€ scraper/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ crawler.py            # ğŸ”— Collects internal links
â”‚   â””â”€â”€ merger.py             # ğŸ§½ Cleans & generates PDF per page
â”œâ”€â”€ main.py                   # ğŸš€ Entry point
â”œâ”€â”€ requirements.txt          # ğŸ“¦ Dependencies
â””â”€â”€ README.md                 # ğŸ“˜ This file
```

---

## âš™ï¸ Prerequisites

- Python 3.8+
- Google Chrome (installed automatically via Playwright)

---

## ğŸ”§ Installation

```bash
# 1. Clone the repository
git clone https://github.com/your-username/reponame.git
cd reponame

# 2. Set up a virtual environment (optional but recommended)
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate

# 3. Install dependencies
pip install -r requirements.txt

# 4. Install Playwright browsers
playwright install
```

---

## ğŸ§ª Run the Scraper

```bash
python main.py
```

Each page will:
- Load in a headless browser
- Be cleaned and simplified
- Be saved as a `.pdf` in the `output/` folder

---

## ğŸ—‚ï¸ Example Output

| URL | Saved As |
|-----|----------|
| `https://javascript.info/` | `output/index.pdf` |
| `https://javascript.info/types` | `output/types.pdf` |
| `https://javascript.info/object/constructor` | `output/object_constructor.pdf` |

---

## ğŸ” Customization Tips

Want to test with fewer pages?

Edit `main.py`:
```python
links = get_internal_links(base_url)
links = links[:10]  # Limit to first 10 pages
```

Want to exclude certain sections?

In `scraper/crawler.py`, add to `UNWANTED_SUBSTRINGS`:
```python
"/feedback", "/rss", ".xml", ".json"
```

---